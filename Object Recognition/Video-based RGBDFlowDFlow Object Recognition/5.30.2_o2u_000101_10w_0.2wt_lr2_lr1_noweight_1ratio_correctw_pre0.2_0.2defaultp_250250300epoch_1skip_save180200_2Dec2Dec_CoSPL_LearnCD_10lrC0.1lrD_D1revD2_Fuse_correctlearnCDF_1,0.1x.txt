/home/wzha8158/Dropbox (Sydney Uni)/2.SPRINT_TSN/tsn-pytorch_SPCAN_real(CODANN)/tf_model_zoo/bninception/pytorch_load.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  manifest = yaml.load(open(model_path))
args Namespace(MaxStep=0, ReTestSource=False, arch='BNInception', batch_size=48, clip_gradient=20.0, consensus_type='avg', crop_fusion_type='avg', dataset='ucf6', decay=0.0003, defaultPseudoRatio=0.2, defaultPseudoRatio2=0.2, diffDFT2=False, diffS=False, dom_weight=0.1, dropout=0.7, dropout2=0.8, epochs=250, epochs2=250, evalBreakIter=200, eval_freq=5, evaluate=False, fixW=False, flow_prefix='flow_', form_w=0.0, form_w2=0.0, gpu=0, gpus=None, k=3, learnCD=True, loss_type='nll', lr=0.002, lr2=0.001, lr_ratio=0.5, lr_steps=[180.0, 230.0], main_w=-0.1, main_w2=-0.1, max_pseudo=1.0, max_pseudo2=0.5, modality='Flow', modality2='RGB', momentum=0.9, nesterov=True, no_partialbn=False, num_segments=3, pre_ratio=0.2, print_freq=20, pseudo_ratio=1.0, pseudo_ratio2=1.0, resume='', reverse_epoch_ratio=1, save_freq=10, select='1-2', skip=1, snapshot_pref='5.30.2_o2u_000101_10w_0.2wt_lr2_lr1_noweight_1ratio_correctw_pre0.2_0.2defaultp_250250300epoch_1skip_save180200_2Dec2Dec_CoSPL_LearnCD_10lrC0.1lrD_D1revD2_Fuse_correctlearnCDF_1,0.1x', sourceTestIter=2000, start_epoch=0, step=0.0003, test_crops=1, test_dropout=0.7, test_segments=15, totalPseudoChange=100, total_epochs=300, train_list='datalist/olympic6_rgb_test_split_1.txt', train_list2='datalist/olympic6_rgb_test_split_2.txt', useCurrentIter=False, useLargeLREpoch=True, usePreT2D=False, usePrevAcc=False, useRatio=False, useSepTrain=True, useT1DorT2='T2', useT1Only=False, useT2CompD=False, usemin=False, usingDoubleDecrease=True, usingDoubleDecrease2=True, usingTriDec=False, usingTriDec2=False, val_list='datalist/ucf6_rgb_train_split_1.txt', val_list2='datalist/ucf6_rgb_train_split_2.txt', weight_decay=0.0005, workers=8, wp=0.055, wt=0.2)

Initializing TSN with base model: BNInception.
TSN Configurations:
    input_modality:     Flow
    num_segments:       3
    new_length:         5
    consensus_module:   avg
    dropout_ratio:      0.7
        
Traceback (most recent call last):
  File "main_cospcan_ratio_2Dec_prev_save_cospl_learnCD.py", line 2339, in <module>
    main()
  File "main_cospcan_ratio_2Dec_prev_save_cospl_learnCD.py", line 126, in main
    form_weight=args.form_w, last_weight=args.main_w, init_w_l2=init_w_l2, init_w_l3=init_w_l3, init_w_l4=init_w_l4, init_w_main=init_w_main)
  File "/home/wzha8158/Dropbox (Sydney Uni)/2.SPRINT_TSN/tsn-pytorch_SPCAN_real(CODANN)/models_cospcan.py", line 220, in __init__
    self._prepare_base_model(base_model)
  File "/home/wzha8158/Dropbox (Sydney Uni)/2.SPRINT_TSN/tsn-pytorch_SPCAN_real(CODANN)/models_cospcan.py", line 314, in _prepare_base_model
    self.base_model = getattr(tf_model_zoo, base_model)()
  File "/home/wzha8158/Dropbox (Sydney Uni)/2.SPRINT_TSN/tsn-pytorch_SPCAN_real(CODANN)/tf_model_zoo/bninception/pytorch_load.py", line 35, in __init__
    self.load_state_dict(torch.utils.model_zoo.load_url(weight_url))
  File "/home/wzha8158/Pytorch0.4py3.5/lib/python3.5/site-packages/torch/nn/modules/module.py", line 719, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for BNInception:
	size mismatch for conv1_7x7_s2_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv1_7x7_s2_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv1_7x7_s2_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv1_7x7_s2_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv2_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv2_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv2_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv2_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for conv2_3x3_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for conv2_3x3_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for conv2_3x3_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for conv2_3x3_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_3a_1x1_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_1x1_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_1x1_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_1x1_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_3x3_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_double_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_double_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_double_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3a_double_3x3_1_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_1_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_1_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_1_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_2_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_2_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_2_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_double_3x3_2_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3a_pool_proj_bn.weight: copying a param of torch.Size([32]) from checkpoint, where the shape is torch.Size([1, 32]) in current model.
	size mismatch for inception_3a_pool_proj_bn.running_mean: copying a param of torch.Size([32]) from checkpoint, where the shape is torch.Size([1, 32]) in current model.
	size mismatch for inception_3a_pool_proj_bn.bias: copying a param of torch.Size([32]) from checkpoint, where the shape is torch.Size([1, 32]) in current model.
	size mismatch for inception_3a_pool_proj_bn.running_var: copying a param of torch.Size([32]) from checkpoint, where the shape is torch.Size([1, 32]) in current model.
	size mismatch for inception_3b_1x1_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_1x1_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_1x1_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_1x1_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_3x3_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_3x3_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_3x3_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_3x3_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_double_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_double_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_double_3x3_1_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_1_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_1_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_1_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_2_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_2_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_2_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_double_3x3_2_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3b_pool_proj_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_pool_proj_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_pool_proj_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3b_pool_proj_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3c_3x3_reduce_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_3c_3x3_reduce_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_3c_3x3_reduce_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_3c_3x3_reduce_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_3c_3x3_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_3c_3x3_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_3c_3x3_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_3c_3x3_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_3c_double_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3c_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3c_double_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3c_double_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_3c_double_3x3_1_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_1_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_1_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_1_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_2_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_2_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_2_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_3c_double_3x3_2_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_1x1_bn.weight: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_4a_1x1_bn.running_mean: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_4a_1x1_bn.bias: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_4a_1x1_bn.running_var: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_4a_3x3_reduce_bn.weight: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_4a_3x3_reduce_bn.running_mean: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_4a_3x3_reduce_bn.bias: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_4a_3x3_reduce_bn.running_var: copying a param of torch.Size([64]) from checkpoint, where the shape is torch.Size([1, 64]) in current model.
	size mismatch for inception_4a_3x3_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_3x3_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_3x3_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_3x3_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_double_3x3_reduce_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_double_3x3_reduce_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_double_3x3_reduce_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4a_double_3x3_1_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_1_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_1_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_1_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_2_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_2_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_2_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_double_3x3_2_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_pool_proj_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_pool_proj_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_pool_proj_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4a_pool_proj_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_1x1_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4b_1x1_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4b_1x1_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4b_1x1_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4b_3x3_reduce_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_3x3_reduce_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_3x3_reduce_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_3x3_reduce_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_3x3_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_3x3_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_3x3_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_3x3_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_reduce_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_double_3x3_reduce_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_double_3x3_reduce_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4b_double_3x3_1_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_1_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_1_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_1_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_2_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_2_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_2_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_double_3x3_2_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_pool_proj_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_pool_proj_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_pool_proj_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4b_pool_proj_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_1x1_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_1x1_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_1x1_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_1x1_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_3x3_reduce_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_3x3_reduce_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_3x3_reduce_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_3x3_reduce_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_3x3_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_3x3_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_3x3_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_3x3_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_reduce_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_double_3x3_reduce_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_double_3x3_reduce_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_double_3x3_1_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_1_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_1_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_1_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_2_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_2_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_2_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_double_3x3_2_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4c_pool_proj_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_pool_proj_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_pool_proj_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4c_pool_proj_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_1x1_bn.weight: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4d_1x1_bn.running_mean: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4d_1x1_bn.bias: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4d_1x1_bn.running_var: copying a param of torch.Size([96]) from checkpoint, where the shape is torch.Size([1, 96]) in current model.
	size mismatch for inception_4d_3x3_reduce_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_3x3_reduce_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_3x3_reduce_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_3x3_reduce_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_3x3_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_3x3_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_3x3_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_3x3_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_reduce_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4d_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4d_double_3x3_reduce_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4d_double_3x3_reduce_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_4d_double_3x3_1_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_1_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_1_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_1_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_2_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_2_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_2_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_double_3x3_2_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4d_pool_proj_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_pool_proj_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_pool_proj_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4d_pool_proj_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4e_3x3_reduce_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4e_3x3_reduce_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4e_3x3_reduce_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4e_3x3_reduce_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_4e_3x3_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_3x3_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_3x3_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_3x3_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_double_3x3_reduce_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_double_3x3_reduce_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_double_3x3_reduce_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_4e_double_3x3_1_bn.weight: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_1_bn.running_mean: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_1_bn.bias: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_1_bn.running_var: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_2_bn.weight: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_2_bn.running_mean: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_2_bn.bias: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_4e_double_3x3_2_bn.running_var: copying a param of torch.Size([256]) from checkpoint, where the shape is torch.Size([1, 256]) in current model.
	size mismatch for inception_5a_1x1_bn.weight: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5a_1x1_bn.running_mean: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5a_1x1_bn.bias: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5a_1x1_bn.running_var: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5a_3x3_reduce_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5a_3x3_reduce_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5a_3x3_reduce_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5a_3x3_reduce_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5a_3x3_bn.weight: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5a_3x3_bn.running_mean: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5a_3x3_bn.bias: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5a_3x3_bn.running_var: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5a_double_3x3_reduce_bn.weight: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_5a_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_5a_double_3x3_reduce_bn.bias: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_5a_double_3x3_reduce_bn.running_var: copying a param of torch.Size([160]) from checkpoint, where the shape is torch.Size([1, 160]) in current model.
	size mismatch for inception_5a_double_3x3_1_bn.weight: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_1_bn.running_mean: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_1_bn.bias: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_1_bn.running_var: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_2_bn.weight: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_2_bn.running_mean: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_2_bn.bias: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_double_3x3_2_bn.running_var: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5a_pool_proj_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5a_pool_proj_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5a_pool_proj_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5a_pool_proj_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5b_1x1_bn.weight: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5b_1x1_bn.running_mean: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5b_1x1_bn.bias: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5b_1x1_bn.running_var: copying a param of torch.Size([352]) from checkpoint, where the shape is torch.Size([1, 352]) in current model.
	size mismatch for inception_5b_3x3_reduce_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_3x3_reduce_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_3x3_reduce_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_3x3_reduce_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_3x3_bn.weight: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5b_3x3_bn.running_mean: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5b_3x3_bn.bias: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5b_3x3_bn.running_var: copying a param of torch.Size([320]) from checkpoint, where the shape is torch.Size([1, 320]) in current model.
	size mismatch for inception_5b_double_3x3_reduce_bn.weight: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_double_3x3_reduce_bn.running_mean: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_double_3x3_reduce_bn.bias: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_double_3x3_reduce_bn.running_var: copying a param of torch.Size([192]) from checkpoint, where the shape is torch.Size([1, 192]) in current model.
	size mismatch for inception_5b_double_3x3_1_bn.weight: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_1_bn.running_mean: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_1_bn.bias: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_1_bn.running_var: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_2_bn.weight: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_2_bn.running_mean: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_2_bn.bias: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_double_3x3_2_bn.running_var: copying a param of torch.Size([224]) from checkpoint, where the shape is torch.Size([1, 224]) in current model.
	size mismatch for inception_5b_pool_proj_bn.weight: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5b_pool_proj_bn.running_mean: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5b_pool_proj_bn.bias: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
	size mismatch for inception_5b_pool_proj_bn.running_var: copying a param of torch.Size([128]) from checkpoint, where the shape is torch.Size([1, 128]) in current model.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Test Epoch: [85]	Time 209.511501074 	Prec@1 61.950	Prec2@1 88.466	Domain 56.171	
sort pseudo time: 0.000324964523315
sort pseudo2 time: 0.000598907470703
sort pseudo_co time: 0.000886917114258
current_test_source_acc 95.5246884381 avg_test_source_acc 92.9942815418 prev_epoch_acc_s 94.5987622296 double_desc False
current_test_source_acc2 99.845678824 avg_test_source_acc2 99.1452251787 prev_epoch_acc_s2 99.0740732264 double_desc2 False
threshold_count: 33 pseudo_ratio:0.3320
threshold2_count: 24 pseudo2_ratio:0.2960
Select error/total selected = 47/368
Select2 error/total selected2 = 25/346
data batch prep_time: 15.5594389439
Epoch: [85][0/27], lr: 0.00086	Time 4.940 (4.940)	Data 0.000 (0.000)	Loss 0.1588 (0.1588)	Prec@1 91.667 (91.667)	Prec2@1 100.000 (100.000)	Domain 60.417 (60.417)	Domain2 62.500 (62.500)	Wmain: 0.100 	Wmain_2: 0.100	l:0.935
clipping gradient: 20.1643911465 with coef 0.991847453003
clipping gradient: 20.6609563415 with coef 0.968009402344
Epoch: [85][20/27], lr: 0.00086	Time 4.970 (4.941)	Data 0.000 (0.000)	Loss 0.1616 (0.1921)	Prec@1 95.833 (94.444)	Prec2@1 100.000 (99.603)	Domain 54.167 (61.210)	Domain2 52.083 (59.325)	Wmain: 0.100 	Wmain_2: 0.100	l:0.935
train_num 36 total_epoch_acc_s 3348.7813329

Epoch 86 lr_decay: 0.212620598785 disc_w_decay: 0.0271893938711
Val Epoch: [86]	Time 47.487639904 	c_rgb 1.019, d_rgb 0.916, fd_rgb 1.112	Prec@1 56.599	Prec2@1 86.088	Domain 55.172	Domain2 86.564	
sort pseudo time: 0.000319004058838
sort pseudo2 time: 0.000590085983276
sort pseudo_co time: 0.000874996185303
current_test_source_acc 93.9814789383 avg_test_source_acc 93.0217036917 prev_epoch_acc_s 95.5246884381 double_desc False
current_test_source_acc2 99.6913576479 avg_test_source_acc2 99.160395525 prev_epoch_acc_s2 99.845678824 double_desc2 False
threshold_count: 34 pseudo_ratio:0.3360
threshold2_count: 25 pseudo2_ratio:0.3000
Select error/total selected = 74/416
Select2 error/total selected2 = 34/357
data batch prep_time: 17.1587910652
Epoch: [86][0/27], lr: 0.00085	Time 4.973 (4.973)	Data 0.000 (0.000)	Loss 0.0853 (0.0853)	Prec@1 95.833 (95.833)	Prec2@1 100.000 (100.000)	Domain 54.167 (54.167)	Domain2 54.167 (54.167)	Wmain: 0.100 	Wmain_2: 0.100	l:0.938
Epoch: [86][20/27], lr: 0.00085	Time 4.918 (4.944)	Data 0.000 (0.000)	Loss 0.1538 (0.1801)	Prec@1 95.833 (94.643)	Prec2@1 100.000 (99.603)	Domain 60.417 (62.599)	Domain2 72.917 (59.921)	Wmain: 0.100 	Wmain_2: 0.100	l:0.938
clipping gradient: 50.298284621 with coef 0.397627874403
train_num 37 total_epoch_acc_s 3442.6084901

Epoch 87 lr_decay: 0.211015909074 disc_w_decay: 0.0265657711771
Val Epoch: [87]	Time 47.7200739384 	c_rgb 1.013, d_rgb 0.914, fd_rgb 1.116	Prec@1 55.767	Prec2@1 82.283	Domain 54.221	Domain2 75.862	
sort pseudo time: 0.000317096710205
sort pseudo2 time: 0.000591039657593
sort pseudo_co time: 0.000876903533936
current_test_source_acc 93.8271571972 avg_test_source_acc 93.0434727054 prev_epoch_acc_s 93.9814789383 double_desc False
current_test_source_acc2 99.5370364719 avg_test_source_acc2 99.1705750101 prev_epoch_acc_s2 99.6913576479 double_desc2 False
threshold_count: 35 pseudo_ratio:0.3400
threshold2_count: 26 pseudo2_ratio:0.3040
Select error/total selected = 76/425
Select2 error/total selected2 = 42/344
data batch prep_time: 17.385212183
Epoch: [87][0/27], lr: 0.00084	Time 5.012 (5.012)	Data 0.000 (0.000)	Loss 0.0564 (0.0564)	Prec@1 100.000 (100.000)	Prec2@1 100.000 (100.000)	Domain 47.917 (47.917)	Domain2 54.167 (54.167)	Wmain: 0.100 	Wmain_2: 0.100	l:0.940
Epoch: [87][20/27], lr: 0.00084	Time 4.992 (4.933)	Data 0.000 (0.000)	Loss 0.1729 (0.1356)	Prec@1 95.833 (94.841)	Prec2@1 95.833 (99.206)	Domain 72.917 (59.028)	Domain2 58.333 (59.226)	Wmain: 0.100 	Wmain_2: 0.100	l:0.940
train_num 38 total_epoch_acc_s 3537.05293172

Epoch 88 lr_decay: 0.209439196679 disc_w_decay: 0.0259564520482
Val Epoch: [88]	Time 47.2534899712 	c_rgb 1.012, d_rgb 0.910, fd_rgb 1.120	Prec@1 55.648	Prec2@1 83.948	Domain 55.291	Domain2 81.213	
sort pseudo time: 0.000324964523315
sort pseudo2 time: 0.000607013702393
sort pseudo_co time: 0.000901937484741
current_test_source_acc 94.4444416187 avg_test_source_acc 93.0803403084 prev_epoch_acc_s 93.8271571972 double_desc False
current_test_source_acc2 99.3827152959 avg_test_source_acc2 99.1761576492 prev_epoch_acc_s2 99.5370364719 double_desc2 False
threshold_count: 36 pseudo_ratio:0.3440
threshold2_count: 27 pseudo2_ratio:0.3080
Select error/total selected = 72/420
Select2 error/total selected2 = 39/355
data batch prep_time: 17.288446188
Epoch: [88][0/27], lr: 0.00084	Time 4.988 (4.988)	Data 0.000 (0.000)	Loss 0.1527 (0.1527)	Prec@1 95.833 (95.833)	Prec2@1 100.000 (100.000)	Domain 58.333 (58.333)	Domain2 64.583 (64.583)	Wmain: 0.100 	Wmain_2: 0.100	l:0.943
clipping gradient: 26.9419776399 with coef 0.742336003219
Epoch: [88][20/27], lr: 0.00084	Time 4.933 (4.956)	Data 0.000 (0.000)	Loss 0.1069 (0.1651)	Prec@1 95.833 (94.048)	Prec2@1 95.833 (99.405)	Domain 60.417 (59.127)	Domain2 64.583 (61.508)	Wmain: 0.100 	Wmain_2: 0.100	l:0.943
train_num 39 total_epoch_acc_s 3631.65169451

Epoch 89 lr_decay: 0.207889702654 disc_w_decay: 0.0253611084142
Val Epoch: [89]	Time 47.5123457909 	c_rgb 1.012, d_rgb 0.909, fd_rgb 1.124	Prec@1 55.886	Prec2@1 78.954	Domain 50.178	Domain2 84.067	
sort pseudo time: 0.00032114982605
sort pseudo2 time: 0.000591993331909
sort pseudo_co time: 0.000875949859619
current_test_source_acc 94.5987627948 avg_test_source_acc 93.1192742183 prev_epoch_acc_s 94.4444416187 double_desc False
current_test_source_acc2 99.3827152959 avg_test_source_acc2 99.1814539991 prev_epoch_acc_s2 99.3827152959 double_desc2 False
threshold_count: 37 pseudo_ratio:0.3480
threshold2_count: 28 pseudo2_ratio:0.3120
Select error/total selected = 95/445
Select2 error/total selected2 = 79/407
data batch prep_time: 18.6964030266
Epoch: [89][0/27], lr: 0.00083	Time 4.969 (4.969)	Data 0.000 (0.000)	Loss 0.0494 (0.0494)	Prec@1 100.000 (100.000)	Prec2@1 100.000 (100.000)	Domain 54.167 (54.167)	Domain2 58.333 (58.333)	Wmain: 0.100 	Wmain_2: 0.100	l:0.945
Epoch: [89][20/27], lr: 0.00083	Time 4.980 (4.963)	Data 0.000 (0.000)	Loss 0.4765 (0.1767)	Prec@1 87.500 (94.643)	Prec2@1 100.000 (99.802)	Domain 58.333 (60.516)	Domain2 72.917 (62.500)	Wmain: 0.100 	Wmain_2: 0.100	l:0.945
train_num 40 total_epoch_acc_s 3726.25045844

Epoch 90 lr_decay: 0.206366695852 disc_w_decay: 0.0247794197297
Val Epoch: [90]	Time 48.8401191235 	c_rgb 1.006, d_rgb 0.907, fd_rgb 1.128	Prec@1 60.048	Prec2@1 82.283	Domain 41.379	Domain2 74.197	
Test Epoch: [90]	Time 209.169126034 	Prec@1 60.761	Prec2@1 81.926	Domain 35.799	
sort pseudo time: 0.000324964523315
sort pseudo2 time: 0.000596046447754
sort pseudo_co time: 0.000875949859619
current_test_source_acc 94.5987639251 avg_test_source_acc 93.156261461 prev_epoch_acc_s 94.5987627948 double_desc False
current_test_source_acc2 99.845678824 avg_test_source_acc2 99.1980596197 prev_epoch_acc_s2 99.3827152959 double_desc2 False
threshold_count: 38 pseudo_ratio:0.3520
threshold2_count: 29 pseudo2_ratio:0.3160
Select error/total selected = 90/469
Select2 error/total selected2 = 45/380
data batch prep_time: 19.1592199802
Epoch: [90][0/27], lr: 0.00083	Time 5.463 (5.463)	Data 0.000 (0.000)	Loss 0.1352 (0.1352)	Prec@1 95.833 (95.833)	Prec2@1 100.000 (100.000)	Domain 64.583 (64.583)	Domain2 62.500 (62.500)	Wmain: 0.100 	Wmain_2: 0.100	l:0.947
clipping gradient: 33.0136033857 with coef 0.605810876394
clipping gradient: 21.0663924485 with coef 0.949379446382
clipping gradient: 31.3606478414 with coef 0.637741927436
clipping gradient: 21.720428987 with coef 0.92079212671
Epoch: [90][20/27], lr: 0.00083	Time 4.890 (4.935)	Data 0.000 (0.000)	Loss 0.3781 (0.1804)	Prec@1 83.333 (94.048)	Prec2@1 100.000 (99.206)	Domain 52.083 (55.853)	Domain2 68.750 (60.417)	Wmain: 0.100 	Wmain_2: 0.100	l:0.947
train_num 41 total_epoch_acc_s 3821.1578633

Epoch 91 lr_decay: 0.20486947165 disc_w_decay: 0.0242110728015
Val Epoch: [91]	Time 47.9401431084 	c_rgb 1.006, d_rgb 0.903, fd_rgb 1.133	Prec@1 54.459	Prec2@1 81.807	Domain 75.981	Domain2 77.765	
sort pseudo time: 0.000313997268677
sort pseudo2 time: 0.000594854354858
sort pseudo_co time: 0.000890016555786
current_test_source_acc 94.9074048643 avg_test_source_acc 93.1989722757 prev_epoch_acc_s 94.5987639251 double_desc False
current_test_source_acc2 99.3827155784 avg_test_source_acc2 99.2025634236 prev_epoch_acc_s2 99.845678824 double_desc2 False
threshold_count: 39 pseudo_ratio:0.3560
threshold2_count: 30 pseudo2_ratio:0.3200
Select error/total selected = 55/391
Select2 error/total selected2 = 59/406
data batch prep_time: 16.8469090462
Epoch: [91][0/27], lr: 0.00082	Time 4.965 (4.965)	Data 0.000 (0.000)	Loss 0.0709 (0.0709)	Prec@1 95.833 (95.833)	Prec2@1 100.000 (100.000)	Domain 56.250 (56.250)	Domain2 62.500 (62.500)	Wmain: 0.100 	Wmain_2: 0.100	l:0.949
